{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGlpwbjtgJPC",
        "outputId": "fcf76d75-fe5f-4e13-e38d-f26c61ec7e2a"
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "LEFT = 0\n",
        "DOWN = 1\n",
        "RIGHT = 2\n",
        "UP = 3\n",
        "\n",
        "N = 5\n",
        "\n",
        "# генерирует поле (есть путь от начала до цели)\n",
        "def generate_random_map(size = N, p = 0.8):\n",
        "    # size: размер квадратного поля\n",
        "    # p: вероятность того, что клетка заморожена\n",
        "        \n",
        "    valid = False\n",
        "\n",
        "    # проверяет, есть ли хотя бы один путь до цели\n",
        "    def is_valid(res):\n",
        "        frontier = []\n",
        "        discovered = set()\n",
        "        frontier.append((0,0)) # добавляем начало пути\n",
        "        while frontier:\n",
        "            r, c = frontier.pop()\n",
        "            if not (r,c) in discovered:\n",
        "                discovered.add((r,c))\n",
        "                directions = [(1, 0), (0, 1), \n",
        "                (-1, 0), (0, -1)]\n",
        "                for x, y in directions:\n",
        "                    r_new = r + x\n",
        "                    c_new = c + y\n",
        "                    if r_new < 0 or r_new >= size or c_new < 0 or c_new >= size:\n",
        "                    # если вышли \n",
        "                    # за границы поля, то игнорируем ход\n",
        "                        continue\n",
        "                    if res[r_new][c_new] == 1: \n",
        "                    # если смогли \n",
        "                    # достичь цели - проверка окончена\n",
        "                        return True\n",
        "                    if (res[r_new][c_new] != -1):  \n",
        "                    # если \n",
        "                    # не попали в лунку - продолжаем \n",
        "                    # ходить по полю\n",
        "                        frontier.append((r_new, c_new))\n",
        "        return False # если так и не нашли цели\n",
        "\n",
        "    while not valid: # генерирует карты,\n",
        "    # пока не получим подходящую\n",
        "        p = min(1, p)\n",
        "        res = np.random.choice([0., -1.], (size, size), p = [p, 1-p])\n",
        "        res[0][0] = 0.\n",
        "        res[-1][-1] = 1.\n",
        "        valid = is_valid(res)\n",
        "    return res\n",
        "\n",
        "def generate_map_and_P(size = N):\n",
        "# сопоставляет каждому состоянию множество четверок: \n",
        "# (вероятность перехода, новое состояние,\n",
        "# награда, ?терминальное состояние)\n",
        "    desc = generate_random_map(size = N)\n",
        "\n",
        "    P = {s : {a : [] for a in range(4)} for s in range(size * size)}\n",
        "\n",
        "    def to_s(row, col):  # преобразует координаты \n",
        "    # поля в номер клетки\n",
        "        return row * size + col\n",
        "\n",
        "    def inc(row, col, a):  # делаем ход \n",
        "    # в зависимости от управления\n",
        "        if a == LEFT:\n",
        "            col = max(col - 1, 0)\n",
        "        elif a == DOWN:\n",
        "            row = min(row + 1, size - 1)\n",
        "        elif a == RIGHT:\n",
        "            col = min(col + 1, size - 1)\n",
        "        elif a == UP:\n",
        "            row = max(row - 1, 0)\n",
        "        return (row, col)\n",
        "\n",
        "    for row in range(size):\n",
        "        for col in range(size):\n",
        "            s = to_s(row, col)\n",
        "            for a in range(4):\n",
        "                li = P[s][a]\n",
        "                letter = desc[row, col]\n",
        "                if letter in [-1, 1]:\n",
        "                    li.append((1.0, s, 0, True))\n",
        "                else:\n",
        "                    for b in [(a - 1) % 4, a, (a + 1) % 4]:\n",
        "                        newrow, newcol = inc(row, col, b)\n",
        "                        newstate = to_s(newrow, newcol)\n",
        "                        newletter = desc[newrow, newcol]\n",
        "                        done = newletter == 1\n",
        "                        if newletter == 1:\n",
        "                            rew = 1.\n",
        "                        elif newletter == -1:\n",
        "                            newstate = s\n",
        "                        else:\n",
        "                            rew = 0.\n",
        "                        if (newstate == s) and  (newstate != 1):\n",
        "                        # остались на месте, значит ударились, получаем штраф\n",
        "                            rew = -0.75 \n",
        "                        if b == a:\n",
        "                            li.append((0.75, newstate, rew, done))\n",
        "                        else:\n",
        "                            li.append((0.125, newstate, rew, done))\n",
        "                        \n",
        "    return P, desc\n",
        "\n",
        "# симулирует шаг из состояния state при выборе действия act\n",
        "def do_step(state, act):\n",
        "    e = np.random.uniform(0, 1)\n",
        "    if e < 0.75:\n",
        "        return P[state][act][1]\n",
        "    elif e < 0.875:\n",
        "        return P[state][act][0]\n",
        "    else:\n",
        "        return P[state][act][2]\n",
        "\n",
        "########################################################\n",
        "\n",
        "# общие параметры и генерация сетки\n",
        "gamma = 0.8 # скидка\n",
        "eps = 1e-10 # порог обучения\n",
        "\n",
        "P, U = generate_map_and_P()\n",
        "U1 = np.copy(U)\n",
        "print(U)\n",
        "print()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0. -1. -1.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.]\n",
            " [-1.  0.  0.  0. -1.]\n",
            " [-1. -1. -1.  0.  0.]\n",
            " [ 0.  0.  0.  0.  1.]]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PK_uDiEKgSiy",
        "outputId": "ff0fa11f-f7ae-44be-8a38-ba5eef2128fc"
      },
      "source": [
        "U = U.reshape(N * N)\n",
        "terms = [] # терминальные состояния\n",
        "for i in range(N * N):\n",
        "    if U[i] in [-1, 1]:\n",
        "        terms.append(i)\n",
        "        if U[i] in [-1, 1]:\n",
        "            U[i] = 0   # в таблице со значениями \n",
        "            # функции Беллмана в терминальных состояниях \n",
        "            # пишем 0, чтобы не суммировать штрафы и \n",
        "            # награду 2 раза\n",
        "\n",
        "# Q-обучение\n",
        "\n",
        "alpha = 0.01 # скорость обучения\n",
        "\n",
        "Q_matrix = np.zeros(N * N * 4).reshape(25, 4).astype(np.float32)\n",
        "print(U1)\n",
        "print()\n",
        "\n",
        "all_states = []\n",
        "for state in range(N * N):\n",
        "    if state not in terms:\n",
        "        all_states.append(state)\n",
        "\n",
        "# процесс заполнения Q-таблицы\n",
        "for episode in range(100000):\n",
        "    #s = random.choice(all_states)\n",
        "    s = 0\n",
        "    for i in range(20):\n",
        "        a = random.choice([0, 1, 2, 3])\n",
        "        _, s_new, rew, done = do_step(s, a)\n",
        "        Q_update = rew + gamma * np.max(Q_matrix[s_new, :])\n",
        "        Q_matrix[s, a] = (1 - alpha) * Q_matrix[s, a] + alpha * Q_update\n",
        "        if done:\n",
        "            break\n",
        "        else:\n",
        "            s = s_new\n",
        "\n",
        "print(Q_matrix)\n",
        "\n",
        "U1 = U1.reshape(N * N)\n",
        "policy = []\n",
        "for state in range(N * N):\n",
        "    if U1[state] == -1:\n",
        "        policy.append('W')\n",
        "        continue\n",
        "    elif U1[state] == 1:\n",
        "        policy.append('G')\n",
        "        continue\n",
        "    optimal_act = np.argmax(Q_matrix[state])\n",
        "    if optimal_act == 0:\n",
        "        policy.append('L')\n",
        "    elif optimal_act == 1:\n",
        "        policy.append('D')\n",
        "    elif optimal_act == 2:\n",
        "        policy.append('R')\n",
        "    elif optimal_act == 3:\n",
        "        policy.append('U')\n",
        "\n",
        "policy = np.reshape(policy, [N, N])\n",
        "print()\n",
        "print(\"Optimal policy:\")\n",
        "print(policy)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0. -1. -1.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.]\n",
            " [-1.  0.  0.  0. -1.]\n",
            " [-1. -1. -1.  0.  0.]\n",
            " [ 0.  0.  0.  0.  1.]]\n",
            "\n",
            "[[-0.91864395 -0.36109677 -0.953498   -1.0406414 ]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [-0.6384234  -0.01410756 -0.11151494 -0.693632  ]\n",
            " [-0.12384152 -0.10780302 -0.7405208  -0.7497409 ]\n",
            " [-0.79003733 -0.77169245 -0.18713766 -0.33669662]\n",
            " [-0.18821898 -0.03282108 -0.06438587 -0.5605558 ]\n",
            " [-0.10292292  0.06682314  0.03573024 -0.50215095]\n",
            " [ 0.06129345  0.16039337  0.02328513 -0.00230656]\n",
            " [-0.01454089 -0.66146076 -0.6999171  -0.17958279]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [-0.6771416  -0.64450794 -0.04439958 -0.10129524]\n",
            " [-0.11141884 -0.46252334  0.0786118   0.05452007]\n",
            " [ 0.1146354   0.25396046 -0.39681655  0.04085151]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.        ]\n",
            " [-0.12996277  0.5224976   0.5620421   0.21660337]\n",
            " [ 0.42752713  0.8076628  -0.0036519  -0.06294113]\n",
            " [-0.3939853  -0.36007732 -0.13642797 -0.27830637]\n",
            " [-0.17662877 -0.43969682 -0.02531915 -0.42316103]\n",
            " [-0.12001903 -0.26724643  0.40677628 -0.27539292]\n",
            " [ 0.2716171   0.04923443  0.79273194  0.4874537 ]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "\n",
            "Optimal policy:\n",
            "[['D' 'W' 'W' 'D' 'D']\n",
            " ['R' 'D' 'D' 'D' 'L']\n",
            " ['W' 'R' 'R' 'D' 'W']\n",
            " ['W' 'W' 'W' 'R' 'D']\n",
            " ['R' 'R' 'R' 'R' 'G']]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}